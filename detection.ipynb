{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"너 정말 병1신 같은 짓 좀 그만해. 이 ㅅ발, 왜 이렇게 일이 꼬이기만 하는 거야? 너 ㅂㅅ처럼 굴지 말고 제대로 좀 해. ㅅㅂ, 내가 왜 이딴 상황에 처하게 된 거야?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['병신', '시발']\n"
     ]
    }
   ],
   "source": [
    "slag_vocab = {\n",
    "    \"slangs\": [\n",
    "        {\n",
    "            \"origin\": \"병신\",\n",
    "            \"meaning\": \"욕설\"\n",
    "        },\n",
    "        {\n",
    "            \"origin\": \"시발\",\n",
    "            \"meaning\": \"욕설\"\n",
    "        },        \n",
    "    ]\n",
    "}\n",
    "\n",
    "slang_list = [ name['origin'] for name in slag_vocab['slangs']]\n",
    "print(slang_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# 한글 자음과 모음을 분리하는 함수\n",
    "def decompose_korean(text):\n",
    "    chosung = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    jungsung = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    jongsung = ['', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "    hangul_base = 44032\n",
    "    hangul_end = 55203\n",
    "\n",
    "    decomposed_text = []\n",
    "    for char in text:\n",
    "        if hangul_base <= ord(char) <= hangul_end:\n",
    "            code = ord(char) - hangul_base\n",
    "            ch = code // 588\n",
    "            j = (code - (ch * 588)) // 28\n",
    "            jl = code % 28\n",
    "            decomposed_text.append(chosung[ch])\n",
    "            decomposed_text.append(jungsung[j])\n",
    "            if jongsung[jl]:\n",
    "                decomposed_text.append(jongsung[jl])\n",
    "        else:\n",
    "            decomposed_text.append(char)\n",
    "    \n",
    "    return ''.join(decomposed_text)\n",
    "\n",
    "def levenshtein_similarity(s1, s2):\n",
    "    distance = Levenshtein.distance(s1, s2)\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    if max_len == 0:\n",
    "        return 1.0  # 두 문자열이 모두 비어 있는 경우, 유사성은 1\n",
    "    similarity = 1 - (distance / max_len)\n",
    "    return similarity\n",
    "\n",
    "def korean_similarity(s1, s2):\n",
    "    decomposed_s1 = decompose_korean(s1)\n",
    "    decomposed_s2 = decompose_korean(s2)\n",
    "    \n",
    "    return levenshtein_similarity(decomposed_s1, decomposed_s2)\n",
    "\n",
    "def sliding_window(text, window_size):\n",
    "    return [text[i:i+window_size] for i in range(len(text) - window_size + 1)]\n",
    "\n",
    "\n",
    "# 중복 제거를 위한 함수\n",
    "def remove_overlapping_results(found_words):\n",
    "    # 유사성이 높은 순으로 정렬\n",
    "    found_words.sort(key=lambda x: -x[3])\n",
    "    idxes = []\n",
    "    seen_ranges = []\n",
    "    for word, window, index, similarity in found_words:\n",
    "        window_range = range(index, index + len(window))\n",
    "        if all(not (set(window_range) & set(existing_range)) for existing_range in seen_ranges):\n",
    "            idxes.append(index)\n",
    "            seen_ranges.append(window_range)\n",
    "    return idxes\n",
    "\n",
    "# 슬라이딩 윈도우 적용 및 유사성 평가\n",
    "def find_similar_words(test_dialogue, slang_list, similarity_threshold=0.55):\n",
    "    found_words = []\n",
    "    for slang in slang_list:\n",
    "        base_window_size = len(slang)\n",
    "        for window_size in range(base_window_size - 2, base_window_size + 3):\n",
    "            if window_size < 1:  # 윈도우 크기가 1보다 작은 경우를 방지\n",
    "                continue\n",
    "            windows = sliding_window(test_dialogue, window_size)\n",
    "            for i, window in enumerate(windows):\n",
    "                similarity = korean_similarity(slang, window)\n",
    "                if similarity > similarity_threshold:\n",
    "                    found_words.append((slang, window, i, similarity))\n",
    "    \n",
    "    # 중복 제거\n",
    "    idxes = remove_overlapping_results(found_words)\n",
    "    print(word, index, similarity)\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시발 21 0.5714285714285714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 23]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_words(text, slang_list, similarity_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'자'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
